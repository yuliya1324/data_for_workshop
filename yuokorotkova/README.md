### Эксперимент с маскированием

**Цель** данного экспериента заключается в том, чтобы проверить понимание модели аргументной структуры предиката через маскирование аргументрв. Мы предположили, что если модель предсказывает слова в том же падеже, в котором стоит таргетный аргумент, то модель верно распознала аргументную структуру.

**Метод и данные**: Эксперимент проводился на моделях T5, Roberta, Bert (tiny, base, large). Таким образом, мы хотели сравнить encoder и encoder-decoder модели, а также модели разных размеров. Для проверки гипотезы аргументы были замаскированы, и модели предсказали по n токенов на месте масок. Дальше для каждого предложения предсказанные токены были отфильтрованы на существительные, и для каждого токена был получен его падеж. Для оценки качества использовалась accuracy метрика (доля верных падежей среди предсказанных токенов). Полученные результаты мы посчитали по семантическим ролям и усреднили по всему датасету.

**Результаты**:

В среднем модели предсказывают аргумент в верном падеже только в 63% случаев. Лучше всего справилась модель `DeepPavlov/rubert-base-cased` (0.68), а хуже всего - `cointegrated/rubert-tiny2` (0.55). При этом роль, которая распознается лучше всего это goal, а хуже всего posessor. Существенной разницы между моделями с разной архитектурой не замечено. 
